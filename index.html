<!doctype html>



  


<html class="theme-next muse use-motion" lang="zh-Hans">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.1" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Keep It Simple Stupid" />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.1" />






<meta name="description" content="深自缄默，如云漂泊">
<meta property="og:type" content="website">
<meta property="og:title" content="OrangeLuyao的小站">
<meta property="og:url" content="https://GeekOrangeLuyao.github.io/index.html">
<meta property="og:site_name" content="OrangeLuyao的小站">
<meta property="og:description" content="深自缄默，如云漂泊">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="OrangeLuyao的小站">
<meta name="twitter:description" content="深自缄默，如云漂泊">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    sidebar: {"position":"left","display":"hide","offset":12,"offset_float":0,"b2t":false,"scrollpercent":false},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://GeekOrangeLuyao.github.io/"/>





  <title>OrangeLuyao的小站</title><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  














</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left 
   page-home 
 ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    
      <div class="site-meta-headline">
        <a>
          <img class="custom-logo-image" src="/images/aaa.jpg"
               alt="OrangeLuyao的小站"/>
        </a>
      </div>
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">OrangeLuyao的小站</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">The world is a fine place, and worth fighting for.I agree with the second part.</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://GeekOrangeLuyao.github.io/src/Voiceprint-Recognization/Article-Speaker-Verification-Using-Adapted-Gaussian/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="OrangeLuYao">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="OrangeLuyao的小站">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/src/Voiceprint-Recognization/Article-Speaker-Verification-Using-Adapted-Gaussian/" itemprop="url">Article: Speaker Verification Using Adapted Gaussian</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-02-07T23:55:42+08:00">
                2019-02-07
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Voiceprint-Recognization/" itemprop="url" rel="index">
                    <span itemprop="name">Voiceprint Recognization</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Article-Speaker-Verification-Using-Adapted-Gaussian"><a href="#Article-Speaker-Verification-Using-Adapted-Gaussian" class="headerlink" title="Article: Speaker Verification Using Adapted Gaussian"></a>Article: Speaker Verification Using Adapted Gaussian</h1><blockquote>
<p>GMM-UBM 的经典论文</p>
</blockquote>
<h2 id="论文情况"><a href="#论文情况" class="headerlink" title="论文情况"></a>论文情况</h2><ol>
<li><p>题目<br>Speaker Verification Using Adapted Gaussian Mixture Models</p>
</li>
<li><p>作者<br>Douglas A. Reynolds, Thomas F. Quatieri, and Robert B. Dunn M.I.T. Lincoln Laboratory, 244 Wood St., Lexington, Massachusetts 02420<br>E-mail: dar@sst.ll.mit.edu, tfq@sst.ll.mit.edu, rbd@sst.ll.mit.edu</p>
</li>
<li><p>摘要</p>
<blockquote>
<p>In this paper we describe the major elements of MIT Lincoln Laboratory’s Gaussian mixture model (GMM)-based speaker verification system used successfully in several NIST Speaker Recognition Evaluations (SREs). The system is built around the likelihood ratio test for verification, using simple but effective GMMs for likelihood functions, a universal background model (UBM) for alternative speaker representation, and a form of Bayesian adaptation to derive speaker models from the UBM. The development and use of a handset detector and score normalization to greatly improve verification performance is also described and discussed. Finally, representative performance benchmarks and system behavior experiments on NIST SRE corpora are presented.</p>
</blockquote>
</li>
<li><p>关键词<br>Key Words: speaker recognition; Gaussian mixture models; likelihood ratio detector; universal background model; handset normalization; NIST evaluation.</p>
</li>
<li><p>引用</p>
<blockquote>
<p>Reynolds, Douglas A., Quatieri, Thomas F., and Dunn, Robert B., Speaker Verification Using Adapted Gaussian Mixture Models, Digital Signal Processing 10 (2000), 19–41.</p>
</blockquote>
</li>
</ol>
<h2 id="论文要点"><a href="#论文要点" class="headerlink" title="论文要点"></a>论文要点</h2><h3 id="1-INTRODUCTION"><a href="#1-INTRODUCTION" class="headerlink" title="1. INTRODUCTION"></a>1. INTRODUCTION</h3><ul>
<li>Over the past several years, Gaussian mixture models (GMMs) have become the dominant approach for modeling in text-independent speaker recognition applications.</li>
</ul>
<h3 id="2-LIKELIHOOD-RATIO-DETECTOR"><a href="#2-LIKELIHOOD-RATIO-DETECTOR" class="headerlink" title="2. LIKELIHOOD RATIO DETECTOR"></a>2. LIKELIHOOD RATIO DETECTOR</h3><ul>
<li><p>定义说话人识别<br>Given a segment of speech, Y, and a hypothesized speaker, S, the task of speaker detection, also referred to as verification, is to determine if Y was spoken by S.</p>
</li>
<li><p>文章定性是single-speaker<br>In this paper we will focus on the core single-speaker detection task.</p>
</li>
<li><p>多speaker的论文如下<br>Discussion of systems that handle the multispeaker detection task can be found in [9].</p>
</li>
<li><p>判定条件<br>The single-speaker detection task can be restated as a basic hypothesis test<br>between $H_0$ and $H_1$</p>
<blockquote>
<p>$H_0$: $Y$ is from the hypothesized speaker $S$<br>$H_1$: $Y$ is not from the hypothesized speaker $S$<br>The optimum test to decide between these two hypotheses is a likelihood ratio<br>test given by<br>$$test = \frac{p(Y|H_0)}{Y|H_1}$$<br>$$test \ge \theta ~ accecpt H_0$$<br>$$test \le \theta ~ reject  H_0$$<br>where $p(Y|H_i), i = 0,1$, is the probability density function for the hypothesis $H_i$ evaluated for the observed speech segment $Y$, also referred to as the likelihood of the hypothesis $H_i$ given the speech segment.</p>
</blockquote>
</li>
</ul>
<p>// TO-DO</p>
<h3 id="3-GMM-UBM-VERIFICATION-SYSTEM"><a href="#3-GMM-UBM-VERIFICATION-SYSTEM" class="headerlink" title="3. GMM-UBM VERIFICATION SYSTEM"></a>3. GMM-UBM VERIFICATION SYSTEM</h3><p>下面介绍整个系统的重要部分</p>
<h4 id="3-1-Gaussian-Mixture-Models"><a href="#3-1-Gaussian-Mixture-Models" class="headerlink" title="3.1 Gaussian Mixture Models"></a>3.1 Gaussian Mixture Models</h4><ul>
<li>选择概率模型<blockquote>
<p>An important step in the implementation of the above likelihood ratio detector is selection of the actual likelihood function, $p(X | \lambda)$.The choice of this function is largely dependent on the features being used as well as specifics of the application.</p>
</blockquote>
</li>
</ul>
<p>For text-independent(文本无关) speaker recognition, where there is no prior knowledge of what the speaker will say, the most successful likelihood function has been Gaussian mixture models.</p>
<p>In text-dependent(文本相关) applications, where there is strong prior knowledge of the spoken text, additional temporal knowledge can be incorporated by using hidden Markov models (HMMs) as the basis for the likelihood function.</p>
<ul>
<li><p>HMM和GMM的比较<br>To date, however, use of more complicated likelihood functions, such as those based on HMMs, has shown no advantage over GMMs for text-independent speaker detection tasks as in the NIST SREs.</p>
</li>
<li><p>模型描述<br>For a D-dimensional feature vector, x, the mixture density used for the likelihood function is defined as:<br>$$p(x | \lambda) = \sum_{i = 1}^{M}w_i p_i(x)$$</p>
</li>
</ul>
<p>The density is a weighted linear combination of M unimodal Gaussian densities, $p_i(x)$, each parameterized by a mean $D \times 1$ vector, $\mu_i$, and a $D \times D$ covariance matrix, $\Sigma_i$:<br>$$p_i(x) = \frac{1}{(2\pi)^{\frac{D}{2}}|\Sigma_i|^{\frac{1}{2}}}exp\left{-\frac{1}{2}(x - \mu_i)^T(\Sigma_i)^{-1}(x - \mu_i)\right}$$</p>
<h4 id="3-2-Front-End-Processing"><a href="#3-2-Front-End-Processing" class="headerlink" title="3.2 Front-End Processing"></a>3.2 Front-End Processing</h4><ul>
<li><p>分帧<br>First, the speech is segmented into frames by a 20-ms window progressing at a 10-ms frame rate.</p>
</li>
<li></li>
</ul>
<h4 id="3-3-Universal-Background-Model"><a href="#3-3-Universal-Background-Model" class="headerlink" title="3.3 Universal Background Model"></a>3.3 Universal Background Model</h4><h4 id="3-4-Adaptation-of-Speaker-Model"><a href="#3-4-Adaptation-of-Speaker-Model" class="headerlink" title="3.4 Adaptation of Speaker Model"></a>3.4 Adaptation of Speaker Model</h4><h4 id="3-5-Log-Likelihood-Ratio-Computation"><a href="#3-5-Log-Likelihood-Ratio-Computation" class="headerlink" title="3.5 Log-Likelihood Ratio Computation"></a>3.5 Log-Likelihood Ratio Computation</h4><h4 id="3-6-Handset-Score-Normalization"><a href="#3-6-Handset-Score-Normalization" class="headerlink" title="3.6 Handset Score Normalization"></a>3.6 Handset Score Normalization</h4><h3 id="4-EXPERIMENTS"><a href="#4-EXPERIMENTS" class="headerlink" title="4. EXPERIMENTS"></a>4. EXPERIMENTS</h3><h3 id="5-CONCLUSIONS-AND-FUTURE-DIRECTIONS"><a href="#5-CONCLUSIONS-AND-FUTURE-DIRECTIONS" class="headerlink" title="5. CONCLUSIONS AND FUTURE DIRECTIONS"></a>5. CONCLUSIONS AND FUTURE DIRECTIONS</h3><h2 id="论文引用"><a href="#论文引用" class="headerlink" title="论文引用"></a>论文引用</h2><p><strong>REFERENCES</strong></p>
<ol>
<li>Rose, R. C. and Reynolds, D. A., Text-independent speaker identification using automatic acoustic segmentation. In Proceedings of the International Conference on Acoustics, Speech, and Signal Processing, 1990, pp. 293–296.</li>
<li>Reynolds, D. A., A Gaussian Mixture Modeling Approach to Text-Independent Speaker Identification. Ph.D. thesis, Georgia Institute of Technology, September 1992.</li>
<li>Reynolds, D. A. and Rose, R. C., Robust text-independent speaker identification using Gaussian mixture speaker models, IEEE Trans. Speech Audio Process. 3 (1995), 72–83.</li>
<li>Reynolds, D. A., Speaker identification and verification using Gaussian mixture speaker models, Speech Commun. 17 (1995), 91–108.</li>
<li>Reynolds, D. A., Automatic speaker recognition using Gaussian mixture speaker models, Lincoln Lab. J. 8 (1996), 173–192.</li>
<li>Doddington, G., Przybocki, M., Martin, A., and Reynolds, D. A., The NIST speaker recognition evaluation—overview, methodology, systems, results, perspective, Speech Commun., in press.</li>
<li>Martin, A. and Przybocki, M., The NIST 1999 speaker recognition evaluation—an overview, Digital Signal Process. 10 (2000), 1–18.</li>
<li>Reynolds, D. A., Comparison of background normalization methods for text-independent<br>speaker verification. In Proceedings of the European Conference on Speech Communication and Technology, September 1997, pp. 963–966.</li>
<li>Dunn, R. B., Reynolds, D. A., and Quatieri, T. F., Approaches to speaker detection and tracking in conversational speech, Digital Signal Process. 10 (2000), 93–112.</li>
<li>Higgins, A., Bahler, L., and Porter, J., Speaker verification using randomized phrase prompting, Digital Signal Process. 1 (1991), 89–106.</li>
<li>Rosenberg, A. E., DeLong, J., Lee, C. H., Juang, B. H., and Soong, F. K., The use of cohort normalized scores for speaker verification. In International Conference on Speech and Language Processing, November 1992, pp. 599–602.</li>
<li>Matsui, T. and Furui, S., Similarity normalization methods for speaker verification based on a posteriori probability. In Proceedings of the ESCA Workshop on Automatic Speaker Recognition, Identification and Verification, 1994, pp. 59–62.</li>
<li>Carey, M., Parris, E., and Bridle, J., A speaker verification system using alphanets. In Proceedings of the International Conference on Acoustics, Speech, and Signal Processing, May 1991, pp. 397–400.</li>
<li>Matsui, T. and Furui, S., Likelihood normalization for speaker verification using a phonemeand speaker-independent model, Speech Commun. 17 (1995), 109–116.</li>
<li>Rosenberg, A. E. and Parthasarathy, S., Speaker background models for connected digit<br>password speaker verification. In Proceedings of the International Conference on Acoustics, Speech, and Signal Processing, May 1996, pp. 81–84.</li>
<li>Heck, L. P. and Weintraub, M., Handset-dependent background models for robust textindependent speaker recognition. In Proceedings of the International Conference on Acoustics, Speech, and Signal Processing, April 1997, pp. 1071–1073.</li>
<li>Dempster, A., Laird, N., and Rubin, D., Maximum likelihood from incomplete data via the EM algorithm, J. Roy. Stat. Soc. 39 (1977), 1–38.</li>
<li>Duda, R. O. and Hart, P. E., Pattern Classification and Scene Analysis. Wiley, New York, 1973. 19. Newman, M., Gillick, L., Ito, Y., McAllaster, D., and Peskin, B., Speaker verification through large vocabulary continuous speech recognition. In Proceedings of the International Conference on Spoken Language Processing, 1996, pp. 2419–2422.</li>
<li>Reynolds, D. A., Rose, R. C., and Smith, M. J. T., PC-based TMS320C30 implementation of the Gaussian mixture model text-independent speaker recognition system. In Proceedings of the International Conference on Signal Processing Applications and Technology, November 1992, pp. 967–973.</li>
<li>Soong, F. K. and Rosenberg, A. E., On the use of instantaneous and transitional spectral information in speaker recognition. In Proceedings of the International Conference on Acoustics, Speech, and Signal Processing, 1986, pp. 877–880.</li>
<li>Reynolds, D. A., Experimental evaluation of features for robust speaker identification, IEEE Trans. Speech Audio Process. 2 (1994), 639–643.</li>
<li>Hermansky, H., Morgan, N., Bayya, A., and Kohn, P., RASTA-PLP speech analysis technique. In Proceedings of the International Conference on Acoustics, Speech, and Signal Processing, March 1992, pp. I.121–I.124.</li>
<li>Reynolds, D. A., The effects of handset variability on speaker recognition performance: Experiments on the switchboard corpus. In Proceedings of the International Conference on Acoustics, Speech, and Signal Processing, May 1996, pp. 113–116.</li>
<li>Quatieri, T., Reynolds, D. A., and O’Leary, G., Magnitude-only estimation of handset nonlinearity with application to speaker recognition. In Proceedings of the International Conference on Acoustics, Speech, and Signal Processing, 1998, pp. 745–748.</li>
<li>Isobe, T. and Takahashi, J., Text-independent speaker verification using virtual speaker based cohort normalization. In Proceedings of the European Conference on Speech Communication and Technology, 1999, pp. 987–990.</li>
<li>Gauvain, J. L. and Lee, C.-H., Maximum a posteriori estimation for multivariate Gaussian mixture observations of Markov chains, IEEE Trans. Speech Audio Process. 2 (1994), 291–298. </li>
<li>Vuuren, S., Speaker Verification in a Time-Feature Space. Ph.D. thesis, Oregon Graduate Institute, March 1999.</li>
<li>Fukunaga,K., Introduction to Statistical Pattern Recognition. Academic Press, San Diego, 1972. </li>
<li>Reynolds, D. A., Zissman, M., Quatieri, T. F., O’Leary, G., and Carlson, B., The effects of telephone transmission degradations on speaker recognition performance. In Proceedings of the International Conference on Acoustics, Speech, and Signal Processing, May 1995, pp. 329–332.</li>
<li>Reynolds, D. A., HTIMIT and LLHDB: Speech corpora for the study of handset transducer<br>effects. In Proceedings of the International Conference on Acoustics, Speech, and Signal<br>Processing, April 1997, pp. 1535–1538.</li>
<li>Linguistic Data Consortium (LDC), Philadelphia, PA. Website: www.ldc.upenn.edu.</li>
<li>NIST speaker recognition evaluation plans, Philadelphia, PA. Website: www.nist.gov/speech/test.htm.</li>
<li>Pryzbocki, M. and Martin, A., The 1999 NIST speaker recognition evaluation, using summed two-channel telephone data for speaker detection and speaker tracking. In Proceedings of the European Conference on Speech Communication and Technology, 1999, pp. 2215–2218.</li>
<li>Martin, A., Doddington, G., Kamm, T., Ordowski, M., and Przybocki, M., The DET curve in assessment of detection task performance. In Proceedings of the European Conference on Speech Communication and Technology, 1997, pp. 1895–1898.</li>
</ol>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://GeekOrangeLuyao.github.io/src/Automatic-Speech-Recognition/MFCC-feature-extraction/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="OrangeLuYao">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="OrangeLuyao的小站">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/src/Automatic-Speech-Recognition/MFCC-feature-extraction/" itemprop="url">MFCC feature extraction</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-02-02T23:05:29+08:00">
                2019-02-02
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Automatic-Speech-Recognition/" itemprop="url" rel="index">
                    <span itemprop="name">Automatic Speech Recognition</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="MFCC"><a href="#MFCC" class="headerlink" title="MFCC"></a>MFCC</h1><p><a href="http://www.speech.cs.cmu.edu/15-492/slides/03_mfcc.pdf" target="_blank" rel="external">PPT下载</a></p>
<h2 id="1-什么是MFCC-特征"><a href="#1-什么是MFCC-特征" class="headerlink" title="1. 什么是MFCC 特征"></a>1. 什么是MFCC 特征</h2><p>在任意一个Automatic speech recognition 系统中，第一步就是提取特征。换句话说，我们需要把音频信号中具有辨识性的成分提取出来，然后把其他的乱七八糟的信息扔掉。<br>MFCCs（Mel Frequency Cepstral Coefficents）是一种在自动语音和说话人识别中广泛使用的特征。<br>下面我们一步步剖析mfcc特征的来历。</p>
<h3 id="1-1-声谱图-Spectrogram"><a href="#1-1-声谱图-Spectrogram" class="headerlink" title="1.1 声谱图(Spectrogram)"></a>1.1 声谱图(Spectrogram)</h3><p>我们处理的是语音信号，那么如何去描述它很重要。因为不同的描述方式放映它不同的信息。那怎样的描述方式才利于我们观测，利于我们理解呢？这里我们先来了解一个叫声谱图的东西。</p>
<p>对于一段语音信号，首先将这些语音进行分帧，通过短时FFT计算，每帧语音都对应于一个频谱，频谱表示频率与能量的关系。</p>
<p>在实际使用中，频谱图有三种，即线性振幅谱、对数振幅谱、自功率谱（对数振幅谱中各谱线的振幅都作了对数计算，所以其纵坐标的单位是dB。这个变换的目的是使那些振幅较低的成分相对高振幅成分得以拉高，以便观察掩盖在低幅噪声中的周期信号）。</p>
<p>得到频谱图是下面几个步骤：</p>
<ol>
<li>按照帧级别的长度对于语音信号进行划分</li>
<li>对于这些短时间的帧做FFT变换</li>
<li>对于得到的FFT结果进行量化</li>
<li>将已有的结果竖着进行排列，这样就得到了所谓的平铺图。</li>
</ol>
<p>声谱图的作用如下：</p>
<ul>
<li>可以按照将时域和频域对比查看</li>
<li>可以将一些因素可视化的展示出来</li>
<li>对于后续的HMM模型有一定的帮助</li>
<li>在TTS系统中有应用</li>
</ul>
<h3 id="1-2-倒谱分析-Cepstrum-Analysis"><a href="#1-2-倒谱分析-Cepstrum-Analysis" class="headerlink" title="1.2 倒谱分析 (Cepstrum Analysis)"></a>1.2 倒谱分析 (Cepstrum Analysis)</h3><p>一个频谱图的峰值就表示语音的主要频率成分，我们把这些峰值称为共振峰（formants），而共振峰就是携带了声音的辨识属性（就是个人身份证一样）。所以它特别重要。用它就可以识别不同的声音。</p>
<p>我们想提取出共振峰的信息，因此我们需要直到共振峰的位置以及他们的转变过程。所以我们需要提取出频谱的包络(envelope),这包络就是一条连接这些共振峰点的平滑曲线。也就是我们需要做下面的事情：</p>
<blockquote>
<p>我们现在有一个频谱图：$Y = log X[k]$<br>现在我们需要求得一个包络：$Y_1 = log H[k]$以及一个震动偏移（频谱细节）：$Y_2 = log E[k]$.<br>我们希望有：$log X[k] = log H[k] + log E[k]$</p>
</blockquote>
<p>那么怎么求呢？<br>我们希望我们的包络符合整个曲线的趋势，剩下的细节只要用频谱减去已求得的包络即可了。既然包络是一个比较平滑的符合走向的曲线，那么自然可以按照一个降噪的思路来做这件事情：</p>
<ul>
<li>将频谱当作一个新的语音信号</li>
<li>将细节当作噪声</li>
<li>这个降噪过程就变成了求包络的过程</li>
</ul>
<p>那么方法也就是非常简单了：</p>
<ol>
<li>将频谱当作一个新的信号</li>
<li>对于这个信号再求一次FFT（注意IFFT的求法，相当于是求了一次IFFT）</li>
<li>随后消除对于这个新的信号的频谱的低频信号（也就是噪声，这只需要一个低通滤波器即可），这样再求回来的时候基本上就是一个不错的包络线了。</li>
</ol>
<p>这样我们就完成了一次倒谱分析。</p>
<h3 id="1-3-梅尔频率分析-Mel-Frequency-Analysis"><a href="#1-3-梅尔频率分析-Mel-Frequency-Analysis" class="headerlink" title="1.3 梅尔频率分析(Mel-Frequency Analysis)"></a>1.3 梅尔频率分析(Mel-Frequency Analysis)</h3><p>我们现在已经求出了包络的情况，下面我们要查看人耳接受声音信号的时候收集到的哪些问题。<br>Mel频率分析就是基于人类听觉感知实验的。实验观测发现人耳就像一个滤波器组一样，它只关注某些特定的频率分量（人的听觉对频率是有选择性的）。也就说，它只让某些频率的信号通过，而压根就直接无视它不想感知的某些频率信号。但是这些滤波器在频率坐标轴上却不是统一分布的，在低频区域有很多的滤波器，他们分布比较密集，但在高频区域，滤波器的数目就变得比较少，分布很稀疏。</p>
<p>换言之，人的听觉系统是一个特殊的非线性系统，它响应不同频率信号的灵敏度是不同的。在语音特征的提取上，人类听觉系统做得非常好，它不仅能提取出语义信息, 而且能提取出说话人的个人特征，这些都是现有的语音识别系统所望尘莫及的。如果在语音识别系统中能模拟人类听觉感知处理特点，就有可能提高语音的识别率。</p>
<p>所以这里的MFCC，也就是梅尔频率倒谱系数（Mel Frequency Cepstrum Coefficient, MFCC）考虑到了人类的听觉特征，先将线性频谱映射到基于听觉感知的Mel非线性频谱中，然后转换到倒谱上。</p>
<p>整个过程：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">graph LR;</div><div class="line">n1(Spectrum);</div><div class="line">n2(Mel-Filters);</div><div class="line">n2(Mel-Spectrum);</div><div class="line"></div><div class="line">n1 --&gt; n2;</div><div class="line">n2 --&gt; n3</div></pre></td></tr></table></figure></p>
<p>总结来说就是我们并不是直接将语音信号做FFT的结果来进行倒谱分析，而是使得语音信号经过一些Mel-Filters之后再进行倒谱分析。</p>
<p>将普通频率转化到Mel频率的公式是：<br>$$mel(f) = 2595 * log_{10}(1 + \frac{f}{700})$$<br>在Mel频域内，人对音调的感知度为线性关系。举例来说，如果两段语音的Mel频率相差两倍，则人耳听起来两者的音调也相差两倍。</p>
<h3 id="1-4-MFCC算法"><a href="#1-4-MFCC算法" class="headerlink" title="1.4 MFCC算法"></a>1.4 MFCC算法</h3><p>我们将频谱通过一组Mel滤波器就得到Mel频谱。公式表述就是：log X[k] = log (Mel-Spectrum)。这时候我们在log X[k]上进行倒谱分析：<br>下面我们来总结一些MFCC算法的流程：</p>
<ol>
<li>先对语音进行预加重、分帧和加窗；（加强语音信号性能（信噪比，处理精度等）的一些预处理）</li>
<li>对每一个短时分析窗，通过FFT得到对应的频谱；（获得分布在时间轴上不同时间窗内的频谱）</li>
<li>将上面的频谱通过Mel滤波器组得到Mel频谱；（通过Mel频谱，将线形的自然频谱转换为体现人类听觉特性的Mel频谱）</li>
<li>在Mel频谱上面进行倒谱分析（取对数，做逆变换，实际逆变换一般是通过DCT离散余弦变换来实现，取DCT后的第2个到第13个系数作为MFCC系数），获得Mel频率倒谱系数MFCC，这个MFCC就是这帧语音的特征；（倒谱分析，获得MFCC作为语音特征）</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line">graph TD;</div><div class="line">n0((输入语音));</div><div class="line">n1((预加重、分帧和加窗));</div><div class="line">n2((FFT));</div><div class="line">n2((取范数));</div><div class="line">n3((Mel-Filter));</div><div class="line">n4((取对数));</div><div class="line">n5((DCT));</div><div class="line">n6((动态特征));</div><div class="line">n7((输出特征向量));</div><div class="line"></div><div class="line">n0 --&gt; n1;</div><div class="line">n1 --&gt; n2;</div><div class="line">n2 --&gt; n3;</div><div class="line">n3 --&gt; n4;</div><div class="line">n4 --&gt; n5;</div><div class="line">n5 --&gt; n6;</div><div class="line">n6 --&gt; n7;</div></pre></td></tr></table></figure>
<p>这时候，语音就可以通过一系列的倒谱向量来描述了，每个向量就是每帧的MFCC特征向量。</p>
<h2 id="2-使用Python对于MFCC进行求解"><a href="#2-使用Python对于MFCC进行求解" class="headerlink" title="2. 使用Python对于MFCC进行求解"></a>2. 使用Python对于MFCC进行求解</h2><p>下面我们使用Python来求一次MFCC特征：</p>
<p>使用的数据是：<a href="http://www.voiptroubleshooter.com/open_speech/" target="_blank" rel="external">OSR data</a> 中的数据<br>为了可以快速出结果，只取前3.5s的语音进行一个简单的实验：</p>
<ol>
<li><p>读语音，取前3.5s</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> numpy</div><div class="line"><span class="keyword">import</span> scipy.io.wavfile</div><div class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</div><div class="line"><span class="keyword">from</span> scipy.fftpack <span class="keyword">import</span> dct</div><div class="line"></div><div class="line">sample_rate,signal=scipy.io.wavfile.read(<span class="string">'OSR_us_000_0010_8k.wav'</span>)</div><div class="line"></div><div class="line">print(sample_rate,len(signal))</div><div class="line"><span class="comment">#读取前3.5s 的数据</span></div><div class="line">signal=signal[<span class="number">0</span>:int(<span class="number">3.5</span>*sample_rate)]</div><div class="line"></div><div class="line">plt.plot(signal)</div><div class="line">plt.show()</div></pre></td></tr></table></figure>
</li>
<li><p>预加重<br>$$y(t)=x(t)−\alpha(t−1)$$</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">pre_emphasis = <span class="number">0.97</span></div><div class="line">emphasized_signal = numpy.append(signal[<span class="number">0</span>], signal[<span class="number">1</span>:] - pre_emphasis * signal[:<span class="number">-1</span>])</div></pre></td></tr></table></figure>
</li>
<li><p>分成短时帧。<br>语音处理范围内的典型帧大小范围为20毫秒到40毫秒，连续帧之间重叠50％（+/- 10％）。流行设置25毫秒的帧大小，frame_size = 0.025和一10毫秒的步幅（15毫秒重叠）， frame_stride = 0.01。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line">frame_size=<span class="number">0.025</span></div><div class="line">frame_stride=<span class="number">0.1</span></div><div class="line">frame_length,frame_step=frame_size*sample_rate,frame_stride*sample_rate</div><div class="line">signal_length=len(emphasized_signal)</div><div class="line">frame_length=int(round(frame_length))</div><div class="line">frame_step=int(round(frame_step))</div><div class="line">num_frames=int(numpy.ceil(float(numpy.abs(signal_length-frame_length))/frame_step))</div><div class="line"></div><div class="line"></div><div class="line">pad_signal_length=num_frames*frame_step+frame_length</div><div class="line">z=numpy.zeros((pad_signal_length-signal_length))</div><div class="line">pad_signal=numpy.append(emphasized_signal,z)</div><div class="line"></div><div class="line">indices = numpy.tile(numpy.arange(<span class="number">0</span>, frame_length), (num_frames, <span class="number">1</span>)) + numpy.tile(numpy.arange(<span class="number">0</span>, num_frames * frame_step, frame_step), (frame_length, <span class="number">1</span>)).T</div><div class="line"></div><div class="line">frames = pad_signal[numpy.mat(indices).astype(numpy.int32, copy=<span class="keyword">False</span>)]</div></pre></td></tr></table></figure>
</li>
<li><p>加窗</p>
<blockquote>
<p>将具有不连续点的周期函数（如矩形脉冲)进行傅立叶级数展开后，选取有限项进行合成。当选取的项数越多，在所合成的波形中出现的峰起越靠近原信号的不连续点。当选取的项数很大时，该峰起值趋于一个常数，大约等于总跳变值的9%。这种现象称为吉布斯效应。</p>
</blockquote>
</li>
</ol>
<p>另外，加窗之后是为了进行傅里叶展开，所有加窗之后，原本没有周期性的语音信号呈现出周期函数的部分特征，抵消FFT所假设的数据是无限的，同时减少频谱泄露。</p>
<p>hamming窗定义如下：<br>$$w(n) = 0.54 - 0.46 cos(2\pi \frac{n}{N}) , 0 \le n \le N$$<br>当然python 的numpy给了hamming函数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">frames *= numpy.hamming(frame_length)</div></pre></td></tr></table></figure>
<ol>
<li><p>傅立叶变换和功率谱<br>我们现在可以做一个在每个帧上计算频谱，这也称为短时傅立叶变换（STFT），其中N通常是256或512。（了解FFT的都明白为什么要这样取值）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">NFFT = <span class="number">512</span></div><div class="line">mag_frames = numpy.absolute(numpy.fft.rfft(frames, NFFT))  <span class="comment"># Magnitude of the FFT</span></div><div class="line"><span class="comment">#print(mag_frames.shape)</span></div><div class="line">pow_frames = ((<span class="number">1.0</span> / NFFT) * ((mag_frames) ** <span class="number">2</span>))  <span class="comment"># Power Spectrum</span></div></pre></td></tr></table></figure>
</li>
<li><p>滤波并转到Mel域上<br>首先利用公式，可知：<br>$$m = 2595 log_{10}(1 + \frac{f}{700}) \Leftrightarrow f = 700(10^{\frac{m}{2595}} - 1)$$</p>
</li>
</ol>
<p>在滤波器组中，每个滤波器都是三角形的，在中心响应处为1，并向0线性减小，直至到达响应为0的两个相邻滤波器的中心频率。具体的形状请参见上面的PDF文档。</p>
<p>从而就是：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line">low_freq_mel = <span class="number">0</span></div><div class="line"><span class="comment">#将频率转换为Mel</span></div><div class="line">nfilt = <span class="number">40</span></div><div class="line">high_freq_mel = (<span class="number">2595</span> * numpy.log10(<span class="number">1</span> + (sample_rate / <span class="number">2</span>) / <span class="number">700</span>))</div><div class="line">mel_points = numpy.linspace(low_freq_mel, high_freq_mel, nfilt + <span class="number">2</span>)  <span class="comment"># Equally spaced in Mel scale</span></div><div class="line">hz_points = (<span class="number">700</span> * (<span class="number">10</span>**(mel_points / <span class="number">2595</span>) - <span class="number">1</span>))  <span class="comment"># Convert Mel to Hz</span></div><div class="line"></div><div class="line">bin = numpy.floor((NFFT + <span class="number">1</span>) * hz_points / sample_rate)</div><div class="line"></div><div class="line">fbank = numpy.zeros((nfilt, int(numpy.floor(NFFT / <span class="number">2</span> + <span class="number">1</span>))))</div><div class="line"></div><div class="line"><span class="keyword">for</span> m <span class="keyword">in</span> range(<span class="number">1</span>, nfilt + <span class="number">1</span>):</div><div class="line">    f_m_minus = int(bin[m - <span class="number">1</span>])   <span class="comment"># left</span></div><div class="line">    f_m = int(bin[m])             <span class="comment"># center</span></div><div class="line">    f_m_plus = int(bin[m + <span class="number">1</span>])    <span class="comment"># right</span></div><div class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> range(f_m_minus, f_m):</div><div class="line">        fbank[m - <span class="number">1</span>, k] = (k - bin[m - <span class="number">1</span>]) / (bin[m] - bin[m - <span class="number">1</span>])</div><div class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> range(f_m, f_m_plus):</div><div class="line">        fbank[m - <span class="number">1</span>, k] = (bin[m + <span class="number">1</span>] - k) / (bin[m + <span class="number">1</span>] - bin[m])</div><div class="line">filter_banks = numpy.dot(pow_frames, fbank.T)</div><div class="line">filter_banks = numpy.where(filter_banks == <span class="number">0</span>, numpy.finfo(float).eps, filter_banks)  <span class="comment"># Numerical Stability</span></div><div class="line">filter_banks = <span class="number">20</span> * numpy.log10(filter_banks)  <span class="comment"># dB</span></div></pre></td></tr></table></figure></p>
<ol>
<li>得到MFCC<br>事实证明，前一步计算出的滤波器组系数高度相关，这在某些机器学习算法中可能存在问题。因此，我们可以应用离散余弦变换（DCT）去相关滤波器组系数并产生滤波器组的压缩表示。通常，对于自动语音识别（ASR），所得到的倒谱系数2-13被保留，其余的被丢弃; num_ceps = 12。丢弃其他系数的原因是它们表示滤波器组系数的快速变化，并且这些细节不会有助于自动语音识别（ASR）。</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">num_ceps = <span class="number">12</span></div><div class="line">mfcc = dct(filter_banks, type=<span class="number">2</span>, axis=<span class="number">1</span>, norm=<span class="string">'ortho'</span>)[:, <span class="number">1</span> : (num_ceps + <span class="number">1</span>)]</div></pre></td></tr></table></figure>
<p>可以将正弦升降1应用于MFCC以降低已被声称在噪声信号中改善语音识别的较高MFCC<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"></div><div class="line">(nframes, ncoeff) = mfcc.shape</div><div class="line"></div><div class="line">n = numpy.arange(ncoeff)</div><div class="line">cep_lifter =<span class="number">22</span></div><div class="line">lift = <span class="number">1</span> + (cep_lifter / <span class="number">2</span>) * numpy.sin(numpy.pi * n / cep_lifter)</div><div class="line">mfcc *= lift  <span class="comment">#*</span></div></pre></td></tr></table></figure></p>
<ol>
<li>平均标准化<br>如前所述，为了平衡频谱并改善信噪比（SNR），我们可以简单地从所有帧中减去每个系数的平均值。对于MFCC也是如此,平均归一化MFCC：<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">mfcc -= (numpy.mean(mfcc, axis=<span class="number">0</span>) + <span class="number">1e-8</span>)</div><div class="line"></div><div class="line">print(mfcc.shape)</div><div class="line">plt.plot(filter_banks)</div><div class="line"></div><div class="line">plt.show()</div></pre></td></tr></table></figure>
</li>
</ol>
<p>最终得到的结果如下:<br><img src="/src/Automatic-Speech-Recognition/MFCC-feature-extraction/1.png" alt="mfcc结果"></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://GeekOrangeLuyao.github.io/src/Machine-Learning-Theory/Gaussian-Mixture-Model/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="OrangeLuYao">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="OrangeLuyao的小站">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/src/Machine-Learning-Theory/Gaussian-Mixture-Model/" itemprop="url">Gaussian Mixture Model</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-02-01T21:23:21+08:00">
                2019-02-01
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Machine-Learning-Theory/" itemprop="url" rel="index">
                    <span itemprop="name">Machine Learning Theory</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Gaussian-Mixture-Model-高斯混合模型"><a href="#Gaussian-Mixture-Model-高斯混合模型" class="headerlink" title="Gaussian Mixture Model 高斯混合模型"></a>Gaussian Mixture Model 高斯混合模型</h1>
          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://GeekOrangeLuyao.github.io/src/programming-tools/Simple-tutorial-for-git/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="OrangeLuYao">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="OrangeLuyao的小站">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/src/programming-tools/Simple-tutorial-for-git/" itemprop="url">Simple tutorial for git</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-01-29T23:24:15+08:00">
                2019-01-29
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/programming-tools/" itemprop="url" rel="index">
                    <span itemprop="name">programming tools</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="简单Git教程"><a href="#简单Git教程" class="headerlink" title="简单Git教程"></a>简单Git教程</h1><p>Git是一个开源的分布式版本控制系统，用于敏捷高效地处理任何或小或大的项目。Git 是 Linus Torvalds 为了帮助管理 Linux 内核开发而开发的一个开放源码的版本控制软件。Git 与常用的版本控制工具 CVS, Subversion 等不同，它采用了分布式版本库的方式，不必服务器端软件支持。</p>
<blockquote>
<p>这里不介绍git 的各个GUI的操作，因为git的丰富功能都是在命令行中的。<br>这里的例子使用的github，但是其他类似的Git服务器都是类似的。</p>
</blockquote>
<h2 id="1-安装"><a href="#1-安装" class="headerlink" title="1. 安装"></a>1. 安装</h2><ol>
<li>对于Linux的系统，大部分的Linux系统都是预装了git，如果没有git也可以通过一些简单的命令快速安装。</li>
<li>对于windows的系统，需要在官网下载安装包，然后安装正常软件的过程进行安装即可，建议是将git安装到全局变量中，因为这方便打开一个命令行，即开即用。本身git的命令都是以git开头的，所以也基本不会和已有的命令重叠。</li>
</ol>
<h2 id="2-使用简明教程"><a href="#2-使用简明教程" class="headerlink" title="2. 使用简明教程"></a>2. 使用简明教程</h2><h3 id="2-1-初始化一个仓库"><a href="#2-1-初始化一个仓库" class="headerlink" title="2.1 初始化一个仓库"></a>2.1 初始化一个仓库</h3><p>在某个目录下面使用命令：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">git init</div></pre></td></tr></table></figure></p>
<p>可以看到当前目录下面多了一个<code>.git</code>文件夹，这就完成了一次初始化。</p>
<h3 id="2-2-检出仓库"><a href="#2-2-检出仓库" class="headerlink" title="2.2 检出仓库"></a>2.2 检出仓库</h3><p>一般而言，需要将已经存在的项目检出到当前的文件夹之下的时候，可以使用如下命令：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 本地项目</span></div><div class="line">git <span class="built_in">clone</span> /path/to/repository </div><div class="line"><span class="comment"># 远程项目</span></div><div class="line">git <span class="built_in">clone</span> username@host:/path/to/repository</div></pre></td></tr></table></figure></p>
<p>注意到，当项目比较大的时候，git的缓存要求比较苛刻，这也是为什么在国内有一些文件特别大的项目进行检出的时候会遭遇到失败的原因。</p>
<h3 id="2-3-提出添加"><a href="#2-3-提出添加" class="headerlink" title="2.3 提出添加"></a>2.3 提出添加</h3><p>你可以使用如下命令提出更改：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 增加某一个文件</span></div><div class="line">git add &lt;filename&gt;</div><div class="line"></div><div class="line"><span class="comment"># 增加当前文件夹下所有的更改</span></div><div class="line">git add *</div></pre></td></tr></table></figure></p>
<h3 id="2-4-本地提交"><a href="#2-4-本地提交" class="headerlink" title="2.4 本地提交"></a>2.4 本地提交</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">git commit -m<span class="string">"comment content"</span></div></pre></td></tr></table></figure>
<p>这个<strong>comment content</strong>的意思是本次commit的一些文字描述。在项目中可以做好规定，以方便与查看修改如何。<br>这个时候，本地的HEAD已经被进行了修改。</p>
<h3 id="2-5-推送改动"><a href="#2-5-推送改动" class="headerlink" title="2.5 推送改动"></a>2.5 推送改动</h3><p>下面我们希望将远程的改动修改到远程的服务器中，一般而言是使用如下命令：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">git push origin master</div></pre></td></tr></table></figure></p>
<p>当然这样就是提交到主分支<strong>master</strong>中，我们也可以对某个分支进行提交，只需要修改master，即可。</p>
<h3 id="2-6-添加远程的仓库"><a href="#2-6-添加远程的仓库" class="headerlink" title="2.6 添加远程的仓库"></a>2.6 添加远程的仓库</h3><p>如果你还没有克隆现有仓库，并欲将你的仓库连接到某个远程服务器，你可以使用如下命令添加：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">git remote add origin &lt;server&gt;</div></pre></td></tr></table></figure></p>
<p>这个server对于github或者gitlab的服务而言，一般可以直接复制，粘贴即可。</p>
<h3 id="2-7-创建分支"><a href="#2-7-创建分支" class="headerlink" title="2.7 创建分支"></a>2.7 创建分支</h3><p>创建一个叫做“feature_x”的分支，并切换过去<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">git checkout -b feature_x</div></pre></td></tr></table></figure></p>
<p>使用<code>git checkout</code>还可以在各个分支间切换，比如切换回主目录：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">git checkout master</div></pre></td></tr></table></figure></p>
<h3 id="2-8-删除分支"><a href="#2-8-删除分支" class="headerlink" title="2.8 删除分支"></a>2.8 删除分支</h3><p>现在要删除某个分支：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">git branch -d feature_x</div></pre></td></tr></table></figure></p>
<h3 id="2-9-更新"><a href="#2-9-更新" class="headerlink" title="2.9 更新"></a>2.9 更新</h3><p>要更新你的本地仓库至最新改动，执行：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">git pull</div></pre></td></tr></table></figure></p>
<p>以在你的工作目录中 获取（fetch） 并 合并（merge） 远端的改动。<br>要合并其他分支到你的当前分支（例如 master），执行：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">git merge &lt;branch&gt;</div></pre></td></tr></table></figure></p>
<p>在这两种情况下，git 都会尝试去自动合并改动。遗憾的是，这可能并非每次都成功，并可能出现冲突（conflicts）。 这时候就需要你修改这些文件来手动合并这些冲突（conflicts）。改完之后，你需要执行<code>git add</code>命令，将结果重新标记为合并成功。<br>在合并改动之前，你可以使用如下命令预览差异：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">git diff &lt;source_branch&gt; &lt;target_branch&gt;</div></pre></td></tr></table></figure></p>
<h3 id="2-10-标签"><a href="#2-10-标签" class="headerlink" title="2.10 标签"></a>2.10 标签</h3><p>为软件发布创建标签是推荐的。因为HEAD名往往是一个比较乱的HASH字符，所以取一个别名可以方便管理。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">git tag 1.0.0 1b2e1d63ff</div></pre></td></tr></table></figure></p>
<p>可以使用下列命令获取提交 ID：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">git <span class="built_in">log</span></div></pre></td></tr></table></figure></p>
<h3 id="2-11-替换本地改动"><a href="#2-11-替换本地改动" class="headerlink" title="2.11 替换本地改动"></a>2.11 替换本地改动</h3><p>假如你操作失误（当然，这最好永远不要发生），你可以使用如下命令替换掉本地改动：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">git checkout -- &lt;filename&gt;</div></pre></td></tr></table></figure></p>
<p>此命令会使用 HEAD 中的最新内容替换掉你的工作目录中的文件。已添加到暂存区的改动以及新文件都不会受到影响。</p>
<p>假如你想丢弃你在本地的所有改动与提交，可以到服务器上获取最新的版本历史，并将你本地主分支指向它：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">git fetch origin</div><div class="line">git reset --hard origin/master</div></pre></td></tr></table></figure></p>
<h2 id="3-高阶内容"><a href="#3-高阶内容" class="headerlink" title="3. 高阶内容"></a>3. 高阶内容</h2><h3 id="3-1-Git工作流"><a href="#3-1-Git工作流" class="headerlink" title="3.1 Git工作流"></a>3.1 Git工作流</h3><p>当初始化一个git文件夹的时候，实际上，我们对于当前文件夹的文件进行了监控，<br>你的本地仓库由 git 维护的三棵“树”组成。第一个是你的<strong>工作目录</strong>，它持有实际文件；第二个是<strong>暂存区（Index）</strong>，它像个缓存区域，临时保存你的改动；最后是<strong>HEAD</strong>，它指向你最后一次提交的结果。</p>
<p>对于一个文件而言，在git 系统中，它有四种情况：</p>
<ol>
<li><p>untracked</p>
<p> 还没被跟踪的文件，表示对于这个文件<code>git add</code>此命令还没有作用过</p>
</li>
<li><p>unmodified</p>
</li>
<li><p>modified</p>
<p> 文件被修改之后，会出现<strong>Changes not staged for commit</strong>这样的字样，这个时候仍然使用<code>git add</code>命令，表示这个文件我已经更新到这个被更改过的版本了。</p>
</li>
<li><p>staged</p>
</li>
</ol>
<p>使用如下命令查看文件的状态：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">git status</div></pre></td></tr></table></figure>
<h3 id="3-2-分支"><a href="#3-2-分支" class="headerlink" title="3.2 分支"></a>3.2 分支</h3><p>分支是用来将特性开发绝缘开来的。在你创建仓库的时候，master 是“默认的”分支。在其他分支上进行开发，完成后再将它们合并到主分支上。</p>
<h3 id="3-3-忽略某些文件"><a href="#3-3-忽略某些文件" class="headerlink" title="3.3 忽略某些文件"></a>3.3 忽略某些文件</h3><p>一般我们总会有些文件无需纳入 Git 的管理，也不希望它们总出现在未跟踪文件列表。通常都是些自动生成的文件，比如日志文件，或者编译过程中创建的临时文件等。我们可以创建一个名为<code>.gitignore</code>的文件列出要忽略的文件模式。</p>
<p>这个具体的写法，请参见<a href="https://git-scm.com/book/zh/v1/Git-%E5%9F%BA%E7%A1%80-%E8%AE%B0%E5%BD%95%E6%AF%8F%E6%AC%A1%E6%9B%B4%E6%96%B0%E5%88%B0%E4%BB%93%E5%BA%93#%E5%BF%BD%E7%95%A5%E6%9F%90%E4%BA%9B%E6%96%87%E4%BB%B6" target="_blank" rel="external">官方文档</a></p>
<h2 id="4-附录"><a href="#4-附录" class="headerlink" title="4. 附录"></a>4. 附录</h2><ol>
<li><a href="https://book.git-scm.com/" target="_blank" rel="external">git 参考书</a></li>
<li><a href="https://help.github.com/" target="_blank" rel="external">github 帮助</a></li>
</ol>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://GeekOrangeLuyao.github.io/src/daily/Hello-World/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="OrangeLuYao">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="OrangeLuyao的小站">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/src/daily/Hello-World/" itemprop="url">Hello World</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-01-29T23:17:29+08:00">
                2019-01-29
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/daily/" itemprop="url" rel="index">
                    <span itemprop="name">daily</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Hello"><a href="#Hello" class="headerlink" title="Hello"></a>Hello</h1><p>Welcome, Here is Orange’s blog.<br>I’m here to share my story with computer science.</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
  </section>

  


          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <section class="site-overview sidebar-panel sidebar-panel-active">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.jpg"
               alt="OrangeLuYao" />
          <p class="site-author-name" itemprop="name">OrangeLuYao</p>
           
              <p class="site-description motion-element" itemprop="description">深自缄默，如云漂泊</p>
          
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives/">
                <span class="site-state-item-count">5</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-categories">
              <a href="/categories/index.html">
                <span class="site-state-item-count">5</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/index.html">
                <span class="site-state-item-count">9</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="mailto:OrangeLuyao@outlook.com" target="_blank" title="E-Mail">
                  
                    <i class="fa fa-fw fa-globe"></i>
                  
                  E-Mail
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="https://space.bilibili.com/36409945/#/" target="_blank" title="Bilibili">
                  
                    <i class="fa fa-fw fa-globe"></i>
                  
                  Bilibili
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="https://www.zhihu.com/people/leo-40-71/activities" target="_blank" title="Zhihu">
                  
                    <i class="fa fa-fw fa-globe"></i>
                  
                  Zhihu
                </a>
              </span>
            
          
        </div>

        
        

        
        
          <div class="links-of-blogroll motion-element links-of-blogroll-block">
            <div class="links-of-blogroll-title">
              <i class="fa  fa-fw fa-globe"></i>
              My Other Blogs
            </div>
            <ul class="links-of-blogroll-list">
              
                <li class="links-of-blogroll-item">
                  <a href="https://blog.csdn.net/kissacm" title="CSDN" target="_blank">CSDN</a>
                </li>
              
                <li class="links-of-blogroll-item">
                  <a href="https://geekvitaminc.github.io/" title="GeekVitaminC" target="_blank">GeekVitaminC</a>
                </li>
              
            </ul>
          </div>
        

        


      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">OrangeLuYao</span>
</div>


<div class="powered-by">
  由 <a class="theme-link" href="https://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Muse
  </a>
</div>


        

        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.1"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.1"></script>



  
  

  
    <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.1"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.1"></script>

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.1"></script>



  


  




	





  





  





  






  





  

  
<script>
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>


  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  


  

  

</body>
</html>
